{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e936ea9-5ef8-4f19-9a66-dd4a2d7f00eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T12:39:02.972443Z",
     "iopub.status.busy": "2021-12-04T12:39:02.972086Z",
     "iopub.status.idle": "2021-12-04T12:39:08.412928Z",
     "shell.execute_reply": "2021-12-04T12:39:08.412146Z",
     "shell.execute_reply.started": "2021-12-04T12:39:02.972402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace data/img_testA/63.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!unzip -q data/data77571/img_test.zip -d data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f9c62d-f290-41c0-9f31-bb3bdba069ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-14T00:50:00.717654Z",
     "iopub.status.busy": "2021-12-14T00:50:00.717014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-14 08:50:02 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 240\n",
      "iters: 30000\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  types:\n",
      "  - type: CrossEntropyLoss\n",
      "lr_scheduler:\n",
      "  end_lr: 0\n",
      "  learning_rate: 0.01\n",
      "  power: 0.9\n",
      "  type: PolynomialDecay\n",
      "model:\n",
      "  align_corners: false\n",
      "  backbone:\n",
      "    channel_ratio: 1.0\n",
      "    min_channel: 16\n",
      "    pretrained: https://bj.bcebos.com/paddleseg/dygraph/mobilenetv2.tar.gz\n",
      "    type: MobileNetV2\n",
      "  backbone_indices:\n",
      "  - 0\n",
      "  - 3\n",
      "  dspp_out_channels: 256\n",
      "  dspp_ratios:\n",
      "  - 1\n",
      "  - 3\n",
      "  - 6\n",
      "  num_classes: 4\n",
      "  pretrained: null\n",
      "  type: DeepLabV3P_DSPP\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 4.0e-05\n",
      "pred_dataset:\n",
      "  num_classes: 4\n",
      "  transforms:\n",
      "  - type: Normalize\n",
      "train_dataset:\n",
      "  dataset_root: /home/aistudio\n",
      "  mode: train\n",
      "  num_classes: 4\n",
      "  train_path: /home/aistudio/train_list.txt\n",
      "  transforms:\n",
      "  - max_scale_factor: 2.0\n",
      "    min_scale_factor: 0.5\n",
      "    scale_step_size: 0.25\n",
      "    type: ResizeStepScaling\n",
      "  - crop_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: RandomPaddingCrop\n",
      "  - type: RandomHorizontalFlip\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "val_dataset:\n",
      "  dataset_root: /home/aistudio\n",
      "  mode: val\n",
      "  num_classes: 4\n",
      "  transforms:\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "  val_path: /home/aistudio/valid_list.txt\n",
      "------------------------------------------------\n",
      "W1214 08:50:02.363309  3882 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W1214 08:50:02.363361  3882 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n",
      "2021-12-14 08:50:06 [INFO]\tLoading pretrained model from https://bj.bcebos.com/paddleseg/dygraph/mobilenetv2.tar.gz\n",
      "2021-12-14 08:50:06 [INFO]\tThere are 260/260 variables loaded into MobileNetV2.\n",
      "2021-12-14 08:50:06 [INFO]\tNumber of predict images = 4608\n",
      "2021-12-14 08:50:07 [INFO]\tLoading pretrained model from output/best_model/model.pdparams\n",
      "2021-12-14 08:50:07 [INFO]\tThere are 351/351 variables loaded into DeepLabV3P_DSPP.\n",
      "2021-12-14 08:50:07 [INFO]\tStart to predict...\n",
      "4100/4608 [=========================>....] - ETA: 28s"
     ]
    }
   ],
   "source": [
    "!python PaddleSeg/predict.py \\\n",
    "        --config PaddleSeg/configs/deeplabv3p/deeplabv3p_mobilenetv2_g.yml \\\n",
    "        --model_path output/best_model/model.pdparams \\\n",
    "        --image_path data/img_testA \\\n",
    "        --aug_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c70b30b4-be05-450a-9fda-85b2d0fdb2ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T14:43:09.802717Z",
     "iopub.status.busy": "2021-12-10T14:43:09.802123Z",
     "iopub.status.idle": "2021-12-10T14:43:09.991407Z",
     "shell.execute_reply": "2021-12-10T14:43:09.990894Z",
     "shell.execute_reply.started": "2021-12-10T14:43:09.802686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4608\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "datas = []\n",
    "image_base = '/home/aistudio/data/img_testA'   # 训练集原图路径\n",
    "files = glob.glob(os.path.join(image_base, '*.jpg'))\n",
    "\n",
    "with open('test_list.txt', 'w') as f:\n",
    "    for img in files:\n",
    "        f.write(img + '\\n')\n",
    "print(len(files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459e3243-9aa6-421b-9ad7-0af1bbdee875",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python PaddleSeg/test.py \\\n",
    "        --config PaddleSeg/configs/deeplabv3p/deeplabv3p_mobilenetv2_g.yml \\\n",
    "        --model_path output/best_model/model.pdparams \\\n",
    "        --image_path test_list.txt \\\n",
    "        --mode_forinfer test \\\n",
    "        --aug_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
